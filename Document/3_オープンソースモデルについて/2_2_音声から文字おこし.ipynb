{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fc903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "from pydub import AudioSegment\n",
    "from pyannote.core import Segment\n",
    "from pyannote.audio import Audio\n",
    "## HugingFaceのAPIトークンを設定\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み(確認用)\n",
    "model = whisper.load_model('small') \n",
    "result = model.transcribe('./meigen01.m4a')\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声のモデリング準備\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3dce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声ファイルの変換(必要)\n",
    "audio = AudioSegment.from_file(\"./meigen01.m4a\", format=\"m4a\")\n",
    "# wavファイルとして保存\n",
    "audio.export(\"meigen01.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87699a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_pathを指定 (wav形式)\n",
    "audio_file=\"meigen01.wav\"\n",
    "# ダイアライゼーション実行\n",
    "diarization = pipeline(audio_file,num_speakers=2)\n",
    "# 音声の読み込み (PyAnnote用)\n",
    "audio = Audio(sample_rate=16000, mono=True)\n",
    "# 音声ファイルの正確な長さを取得（フレーム数 → 秒）\n",
    "waveform_all, sample_rate = audio(audio_file)\n",
    "duration_exact = waveform_all.shape[1] / sample_rate\n",
    "# モデルの読み込み\n",
    "model = whisper.load_model('small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を保存するファイル名\n",
    "output_path = \"voice_to_text.txt\"\n",
    "MAX_TOLERANCE = 0.3\n",
    "# 書き込み用にファイルを開く\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "  for segment, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    start = segment.start\n",
    "    end = segment.end\n",
    "    # 長さ超過時の処理\n",
    "    overshoot = end - duration_exact\n",
    "    if overshoot > 0:\n",
    "      if overshoot <= MAX_TOLERANCE:\n",
    "        end = duration_exact\n",
    "      else:\n",
    "        # 長さ超過が許容範囲を超える場合はスキップ\n",
    "        print(f\"スキップ: セグメント {end:.3f}s は音声長 {duration_exact:.3f}s を {overshoot:.3f}s 超過\")\n",
    "        continue\n",
    "    safe_segment = Segment(start, end)\n",
    "    try:\n",
    "      waveform, sample_rate = audio.crop(audio_file, safe_segment)\n",
    "    except Exception as e:\n",
    "      print(f\"cropエラー: {e}\")\n",
    "      continue\n",
    "    # 音声認識（numpy → Whisper）\n",
    "    try:\n",
    "      text = model.transcribe(waveform.squeeze().numpy())[\"text\"]\n",
    "    except Exception as e:\n",
    "      print(f\"認識エラー: {e}\")\n",
    "      text = \"\"\n",
    "    # 結果の出力\n",
    "    line = f\"[{safe_segment.start:03.1f}s - {safe_segment.end:03.1f}s] {speaker}: {text}\"\n",
    "    print(line)\n",
    "    f.write(line + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
